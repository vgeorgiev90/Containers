# Default values for hadoop.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.


images:
  zookeeper: zookeeper:latest
  namenode: viktor90/hadoop:namenode
  datanode: bde2020/hadoop-datanode:2.0.0-hadoop3.1.2-java8
  resourcemanager: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.1.2-java8
  nodemanager: bde2020/hadoop-nodemanager:2.0.0-hadoop3.1.2-java8
  historyserver: bde2020/hadoop-historyserver:2.0.0-hadoop3.1.2-java8
  journalnode: viktor90/hadoop:journalnode

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

services:
  type: ClusterIP

journalnodes:
  storage: 1Gi

namenodes:
  storage: 1Gi

historyserver:
  storage: 1Gi

zookeeper:
  storage: 1Gi
## Number of datanode replicas , pod anti affinity is configured so set as the number of workers.
datanodes: 
  count: 3
  storage: 2Gi

ingress:
  enabled: enabled
  annotations: {}
  #kubernetes.io/ingress.class: nginx
  #nginx.ingress.kubernetes.io/proxy-body-size: "0"
  #nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
  #nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
  historyserver_host: historyserver.endava.local
  namenode_host: hadoop.endava.local

  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local



hadoop_env_config:
  cluster_name: "test"
  CORE_CONF_fs_defaultFS: "hdfs://hacluster"
  CORE_CONF_hadoop_http_staticuser_user: "root"
  CORE_CONF_hadoop_proxyuser_hue_hosts: "*"
  CORE_CONF_hadoop_proxyuser_hue_groups: "*"
  CORE_CONF_io_compression_codecs: "org.apache.hadoop.io.compress.SnappyCodec"


  HDFS_CONF_dfs_webhdfs_enabled: "true"
  HDFS_CONF_dfs_permissions_enabled: "false"
  HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check: "false"

  YARN_CONF_yarn_log___aggregation___enable: "true"
  YARN_CONF_yarn_log_server_url: "http://hadoop-historyserver:8188/applicationhistory/logs/"
  YARN_CONF_yarn_resourcemanager_recovery_enabled: "true"
  YARN_CONF_yarn_resourcemanager_store_class: "org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore"
  YARN_CONF_yarn_resourcemanager_scheduler_class: "org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler"
  YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb: "8192"
  YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores: "4"
  YARN_CONF_yarn_resourcemanager_fs_state___store_uri: "/rmstate"
  YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled: "true"
  YARN_CONF_yarn_resourcemanager_hostname: "hadoop-resourcemanager-0.hadoop-resourcemanager"
  YARN_CONF_yarn_resourcemanager_address: "hadoop-resourcemanager-0.hadoop-resourcemanager:8032"
  YARN_CONF_yarn_resourcemanager_scheduler_address: "hadoop-resourcemanager-0.hadoop-resourcemanager:8030"
  YARN_CONF_yarn_resourcemanager_resource__tracker_address: "hadoop-resourcemanager-0.hadoop-resourcemanager:8031"
  YARN_CONF_yarn_timeline___service_enabled: "true"
  YARN_CONF_yarn_timeline___service_generic___application___history_enabled: "true"
  YARN_CONF_yarn_timeline___service_hostname: "hadoop-historyserver-0.hadoop-historyserver"
  YARN_CONF_mapreduce_map_output_compress: "true"
  YARN_CONF_mapred_map_output_compress_codec: "org.apache.hadoop.io.compress.SnappyCodec"
  YARN_CONF_yarn_nodemanager_resource_memory___mb: "16384"
  YARN_CONF_yarn_nodemanager_resource_cpu___vcores: "8"
  YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage: "98.5"
  YARN_CONF_yarn_nodemanager_remote___app___log___dir: "/app-logs"
  YARN_CONF_yarn_nodemanager_aux___services: "mapreduce_shuffle"

  MAPRED_CONF_mapreduce_framework_name: "yarn"
  MAPRED_CONF_mapred_child_java_opts: "-Xmx4096m"
  MAPRED_CONF_mapreduce_map_memory_mb: "4096"
  MAPRED_CONF_mapreduce_reduce_memory_mb: "8192"
  MAPRED_CONF_mapreduce_map_java_opts: "-Xmx3072m"
  MAPRED_CONF_mapreduce_reduce_java_opts: "-Xmx6144m"
  MAPRED_CONF_yarn_app_mapreduce_am_env: "HADOOP_MAPRED_HOME=/opt/hadoop-3.1.2/"
  MAPRED_CONF_mapreduce_map_env: "HADOOP_MAPRED_HOME=/opt/hadoop-3.1.2/"
  MAPRED_CONF_mapreduce_reduce_env: "HADOOP_MAPRED_HOME=/opt/hadoop-3.1.2/"



resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi
resources_datanode: {}

resources_zookeeper: {}

nodeSelector: {}
#  app: hadoop

tolerations: {}
#  - key: "node-role.kubernetes.io/master"
#    operator: "Exists"
#    effect: "NoSchedule"

